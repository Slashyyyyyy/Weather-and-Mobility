{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5687ae4-63e4-44bd-bc3e-543673b2d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get station data\n",
    "import pandas as pd\n",
    "\n",
    "stationen = pd.read_csv(\"./Data/Verzeichnis der Verkehrsstationen.csv\", sep = \";\")\n",
    "stationen = stationen.drop(range(1038,1058)) #these are NaNs\n",
    "replace_map = {\n",
    "    \" a.d.L.\": \"/Leitha\",\n",
    "    \" a.d.\": \"/\", \n",
    "    \" a d\": \"/\",\n",
    "    \"N.Ö.\": \"NÖ\",\n",
    "    #\"St.\": \"St. \",\n",
    "    \"Westbf\": \"Westbahnhof\",\n",
    "    \"Ostbf\": \"Ostbahnhof\",\n",
    "    \"Obertrattnach-M Hofk\": \"Obertrattnach-Markt Hofkirchen\",\n",
    "    \"Wien Hauptbahnhof, Wien Hauptbahnhof Südtiroler Platz\": \"Wien Hbf\",\n",
    "    \"Wien Mitte, Wien Mitte - CAT\": \"Wien Mitte\",\n",
    "    \"Wörthersee\": \"Wörther_See\",\n",
    "    \" \": \"_\",\n",
    "    \"-\": \"_\"\n",
    "}\n",
    "\n",
    "def replace_text(text):\n",
    "    for old, new in replace_map.items():\n",
    "        text = text.replace(old, new)\n",
    "    return text\n",
    "    \n",
    "stationen[\"Verkehrsstation\"] = stationen[\"Verkehrsstation\"].apply(replace_text)\n",
    "stations = sorted(stationen[\"Verkehrsstation\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2327231d-9c35-424e-9f83-c0923c16816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress File\n",
    "\n",
    "# If the progress file was not saved correctly and a code restart is needed enter last_station and last_date from your 2years_train_schedule here.\n",
    "# Usually happens when the browser has no more memory space.\n",
    "\n",
    "import json\n",
    "\n",
    "#progress = {\n",
    "#    \"last_station\": None\n",
    "#    \"last_date\": None\n",
    "#}\n",
    "\n",
    "#with open(\"./progress_checkpoint.json\", \"w\") as f:\n",
    "#    json.dump(progress, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80ee6b94-63be-45d5-a570-4241a95e9930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get time range\n",
    "import datetime as dt\n",
    "\n",
    "date_range = []\n",
    "start_date = dt.datetime(2023, 1, 1)  \n",
    "end_date = dt.datetime(2025, 1, 1)\n",
    "\n",
    "for x in range((end_date-start_date).days + 1):\n",
    "    date = start_date + dt.timedelta(days = x)\n",
    "    date_range.append(date.strftime(\"%Y%m%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8af061f9-ff41-499d-b10d-50a01640f2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data collection complete!\n"
     ]
    }
   ],
   "source": [
    "# Where the Magic begins\n",
    "import requests, bs4, csv, time, json, logging\n",
    "\n",
    "# Configure logging to capture errors\n",
    "logging.basicConfig(filename = \"errors_p5.log\", level = logging.ERROR)\n",
    "\n",
    "# Defining url header (for also capturing historic data)\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br, zstd\",\n",
    "    \"Accept-Language\": \"de,de-DE;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6\",\n",
    "    \"Cache-Control\": \"max-age=0\",\n",
    "    \"Cookie\": None #actuall cookie requiered with access to Pro version, turned into None for data security reasons\n",
    "}             \n",
    "\n",
    "# Open the final csv document for appending \n",
    "with open(\"./Data/Train/Part_5_2years_train_schedule.csv\", mode = \"a\", newline = \"\", encoding = \"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Write header if it doesn't already exist\n",
    "    if file.tell() == 0:\n",
    "        writer.writerow([\"Station\", \"Date\", \"Arrival\", \"Train Nr.\", \"Departure from\", \"Arrival train station\"])\n",
    "  \n",
    "    # Iterate trough all the stations    \n",
    "    for station in stations_with_an_der: # reversed(stations) => if traversal from the bottom is wanted\n",
    "\n",
    "        # Open Progress file\n",
    "        with open(\"./progress_checkpoint.json\", \"r\") as f:\n",
    "            progress = json.load(f)\n",
    "        last_processed_station = progress[\"last_station\"]\n",
    "        \n",
    "        if not last_processed_station or station >= last_processed_station: # < for reversed; > for normal use\n",
    "            \n",
    "            # Iterate through date range for each station\n",
    "            for current_date in date_range: \n",
    "                \n",
    "                with open(\"./progress_checkpoint.json\", \"r\") as f:\n",
    "                    progress = json.load(f)\n",
    "                last_processed_date = progress[\"last_date\"]\n",
    "\n",
    "                if not last_processed_date or current_date >= last_processed_date: \n",
    "\n",
    "                    # Establish exception variables\n",
    "                    retry_count = 0\n",
    "                    max_retries = 3\n",
    "                    backoff = 0.5 \n",
    "\n",
    "                    # Create retry loop for connection errors\n",
    "                    while retry_count < max_retries:\n",
    "                        try:\n",
    "                            # Get response from website\n",
    "                            url = f\"https://www.zugfinder.net/de/bahnhofstafel-{station}-{current_date}-arr\"\n",
    "                            #print(url)\n",
    "                            time.sleep(backoff)\n",
    "                            response = requests.get(url, headers = headers)\n",
    "\n",
    "                            # Escape retrys for certain status codes of the website, as there is no use in retrys\n",
    "                            if 400 <= response.status_code < 500:\n",
    "                                print(f\"Client error ({response.status_code}): {url}\")\n",
    "                                logging.error(f\"Client error ({response.status_code}): {url}\")\n",
    "                                break\n",
    "\n",
    "                            # Find data in html\n",
    "                            soup = bs4.BeautifulSoup(response.content, \"html.parser\")\n",
    "                            table = soup.find(\"table\", {\"id\": \"zugdaten\"})\n",
    "\n",
    "                            # Escape retry, if table is empty\n",
    "                            if table is None:\n",
    "                                progress = {\"last_station\": station}\n",
    "                                next_date_index = (date_range.index(current_date) + 1) % len(date_range)\n",
    "                                progress[\"last_date\"] = date_range[next_date_index]\n",
    "                                with open(\"./progress_checkpoint.json\", \"w\") as f:\n",
    "                                    json.dump(progress, f)\n",
    "                                break\n",
    "                        \n",
    "                            # Write data in csv document\n",
    "                            rows = table.find_all(\"tr\")[1:] # first one is just initializing\n",
    "                            for row in rows:\n",
    "                                row_data = []\n",
    "                                cells = row.find_all(\"td\")\n",
    "                                for cell in cells:\n",
    "                                    row_data.append(cell.text.strip())    \n",
    "                                writer.writerow([station, current_date] + row_data)\n",
    "\n",
    "                            # Update progress\n",
    "                            progress = {\"last_station\": station}\n",
    "                            next_date_index = (date_range.index(current_date) + 1) % len(date_range)\n",
    "                            progress[\"last_date\"] = date_range[next_date_index]\n",
    "                            with open(\"./progress_checkpoint.json\", \"w\") as f:\n",
    "                                json.dump(progress, f)\n",
    "\n",
    "                            # Exit retry, if successfull\n",
    "                            break\n",
    "                    \n",
    "                        except Exception as e:\n",
    "                            # Increase exception variables and log error\n",
    "                            retry_count += 1\n",
    "                            backoff *= 2  \n",
    "                            print(f\"Error processing URL: {url} (Attempt {retry_count}/{max_retries})\\n{e}\")\n",
    "                            logging.error(f\"Error processing URL: {url} (Attempt {retry_count}/{max_retries})\\n{e}\")\n",
    "\n",
    "                    # Information after failed retry\n",
    "                    if retry_count == max_retries:\n",
    "                        print(f\"Failed to process city: {station}, date: {current_date} after {max_retries} attempts. Skipping...\")\n",
    "\n",
    "                        # Update progress after failed attempt\n",
    "                        progress = {\"last_station\": station}\n",
    "                        next_date_index = (date_range.index(current_date) + 1) % len(date_range)\n",
    "                        progress[\"last_date\"] = date_range[next_date_index]\n",
    "                        with open(\"./progress_checkpoint.json\", \"w\") as f:\n",
    "                            json.dump(progress, f)   \n",
    "# Data collection complete                   \n",
    "print(\"Data collection complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
